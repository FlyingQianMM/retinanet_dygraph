W0813 06:06:38.204668 41038 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 9.0
W0813 06:06:38.209476 41038 device_context.cc:269] device: 0, cuDNN Version: 7.2.
-----------  Configuration Arguments -----------
batch_size_per_im: 512
class_num: 81
data_dir: dataset/coco
dataset: coco2017
draw_threshold: 0.8
enable_ce: False
im_per_batch: 2
image_path: dataset/coco/val2017
learning_rate: 0.00125
log_window: 20
max_iter: 720000
max_size: 1333
model_save_dir: output
nms_thresh: 0.5
num_gpus: 1
padding_minibatch: False
pixel_means: [102.9801, 115.9465, 122.7717]
pretrained_model: imagenet_resnet50_fusebn
scales: [800]
score_thresh: 0.05
snapshot_stride: 40000
use_data_parallel: 0
use_flipped: True
use_gpu: True
------------------------------------------------
No optimizer loaded. If you didn't save optimizer, please ignore this. The program can still work with new optimizer. 
loading annotations into memory...
Done (t=30.50s)
creating index...
index created!
_add_gt_annotations took 44.424s
Appending horizontally-flipped training examples...
Loaded dataset: coco2017
236574 roidb entries
Filtered 2042 roidb entries: 236574 -> 234532
train on coco2017 with 236574 roidbs
loading annotations into memory...
Done (t=1.28s)
creating index...
index created!
Loaded dataset: coco2017
5000 roidb entries
val on coco2017 with 5000 roidbs
python op time: 73.0104269981
2019-08-13 06:10:15.802064, iter: 0, lr: [0.00041667] 'loss_bbox': 0.477, 'loss': 1.703, 'loss_cls': 1.226, time: 75.373
python op time: 242.978976965
2019-08-13 06:14:19.417550, iter: 1, lr: [0.00041708] 'loss_bbox': 0.493, 'loss': 1.68, 'loss_cls': 1.186, time: 243.568
python op time: 66.3747150898
2019-08-13 06:15:26.498094, iter: 2, lr: [0.0004175] 'loss_bbox': 0.477, 'loss': 1.687, 'loss_cls': 1.211, time: 67.028
python op time: 19.8161838055
2019-08-13 06:15:46.980293, iter: 3, lr: [0.00041792] 'loss_bbox': 0.476, 'loss': 1.695, 'loss_cls': 1.218, time: 20.426
python op time: 195.698162079
2019-08-13 06:19:03.419957, iter: 4, lr: [0.00041833] 'loss_bbox': 0.477, 'loss': 1.687, 'loss_cls': 1.211, time: 196.387
python op time: 71.1752119064
2019-08-13 06:20:15.315187, iter: 5, lr: [0.00041875] 'loss_bbox': 0.476, 'loss': 1.672, 'loss_cls': 1.191, time: 71.809
python op time: 96.1318311691
2019-08-13 06:21:52.123145, iter: 6, lr: [0.00041917] 'loss_bbox': 0.476, 'loss': 1.657, 'loss_cls': 1.171, time: 96.749
python op time: 238.859462023
2019-08-13 06:25:51.718929, iter: 7, lr: [0.00041958] 'loss_bbox': 0.47, 'loss': 1.655, 'loss_cls': 1.159, time: 239.539
python op time: 28.1243000031
2019-08-13 06:26:20.467458, iter: 8, lr: [0.00042] 'loss_bbox': 0.476, 'loss': 1.657, 'loss_cls': 1.171, time: 28.690
python op time: 215.25009799
2019-08-13 06:29:56.420610, iter: 9, lr: [0.00042042] 'loss_bbox': 0.473, 'loss': 1.655, 'loss_cls': 1.162, time: 215.885
python op time: 84.4696919918
2019-08-13 06:31:21.757288, iter: 10, lr: [0.00042083] 'loss_bbox': 0.475, 'loss': 1.657, 'loss_cls': 1.171, time: 85.286
python op time: 119.636400223
2019-08-13 06:33:22.090039, iter: 11, lr: [0.00042125] 'loss_bbox': 0.475, 'loss': 1.668, 'loss_cls': 1.176, time: 120.262
python op time: 99.895637989
2019-08-13 06:35:02.694796, iter: 12, lr: [0.00042167] 'loss_bbox': 0.475, 'loss': 1.657, 'loss_cls': 1.181, time: 100.554
python op time: 109.735293865
2019-08-13 06:36:53.128066, iter: 13, lr: [0.00042208] 'loss_bbox': 0.473, 'loss': 1.655, 'loss_cls': 1.181, time: 110.368
python op time: 53.7757508755
2019-08-13 06:37:47.564594, iter: 14, lr: [0.0004225] 'loss_bbox': 0.475, 'loss': 1.657, 'loss_cls': 1.181, time: 54.383
python op time: 54.7959849834
2019-08-13 06:38:43.174820, iter: 15, lr: [0.00042292] 'loss_bbox': 0.473, 'loss': 1.668, 'loss_cls': 1.196, time: 55.546
python op time: 187.73938489
2019-08-13 06:41:51.697649, iter: 16, lr: [0.00042333] 'loss_bbox': 0.475, 'loss': 1.657, 'loss_cls': 1.181, time: 188.449
python op time: 69.4689860344
2019-08-13 06:43:01.919387, iter: 17, lr: [0.00042375] 'loss_bbox': 0.475, 'loss': 1.668, 'loss_cls': 1.196, time: 70.170
python op time: 80.4132139683
2019-08-13 06:44:23.149238, iter: 18, lr: [0.00042417] 'loss_bbox': 0.476, 'loss': 1.68, 'loss_cls': 1.211, time: 81.163
python op time: 143.148864985
2019-08-13 06:46:47.054329, iter: 19, lr: [0.00042458] 'loss_bbox': 0.475, 'loss': 1.668, 'loss_cls': 1.196, time: 143.857
python op time: 40.238984108
2019-08-13 06:47:27.976101, iter: 20, lr: [0.000425] 'loss_bbox': 0.473, 'loss': 1.668, 'loss_cls': 1.196, time: 40.841
python op time: 19.8088448048
2019-08-13 06:47:48.437098, iter: 21, lr: [0.00042542] 'loss_bbox': 0.473, 'loss': 1.683, 'loss_cls': 1.212, time: 20.406
python op time: 65.7948651314
2019-08-13 06:48:54.879525, iter: 22, lr: [0.00042583] 'loss_bbox': 0.469, 'loss': 1.667, 'loss_cls': 1.197, time: 66.385
python op time: 58.3808591366
2019-08-13 06:49:54.236775, iter: 23, lr: [0.00042625] 'loss_bbox': 0.473, 'loss': 1.667, 'loss_cls': 1.197, time: 59.311
python op time: 60.944396019
2019-08-13 06:50:56.060922, iter: 24, lr: [0.00042667] 'loss_bbox': 0.469, 'loss': 1.681, 'loss_cls': 1.216, time: 61.758
python op time: 77.3446428776
2019-08-13 06:52:14.121210, iter: 25, lr: [0.00042708] 'loss_bbox': 0.473, 'loss': 1.7, 'loss_cls': 1.216, time: 78.013
python op time: 33.2987270355
2019-08-13 06:52:48.087032, iter: 26, lr: [0.0004275] 'loss_bbox': 0.473, 'loss': 1.718, 'loss_cls': 1.23, time: 33.918
python op time: 32.9406070709
2019-08-13 06:53:21.816654, iter: 27, lr: [0.00042792] 'loss_bbox': 0.477, 'loss': 1.72, 'loss_cls': 1.241, time: 33.675
python op time: 77.1693809032
2019-08-13 06:54:39.856227, iter: 28, lr: [0.00042833] 'loss_bbox': 0.477, 'loss': 1.72, 'loss_cls': 1.23, time: 77.962
python op time: 129.314268112
2019-08-13 06:56:49.904260, iter: 29, lr: [0.00042875] 'loss_bbox': 0.477, 'loss': 1.72, 'loss_cls': 1.23, time: 129.997
python op time: 64.4505290985
2019-08-13 06:57:54.988167, iter: 30, lr: [0.00042917] 'loss_bbox': 0.476, 'loss': 1.719, 'loss_cls': 1.22, time: 65.038
python op time: 48.767343998
2019-08-13 06:58:44.425761, iter: 31, lr: [0.00042958] 'loss_bbox': 0.47, 'loss': 1.719, 'loss_cls': 1.22, time: 49.374
python op time: 135.187031031
2019-08-13 07:01:00.284864, iter: 32, lr: [0.00043] 'loss_bbox': 0.47, 'loss': 1.719, 'loss_cls': 1.22, time: 135.797
python op time: 186.567991018
2019-08-13 07:04:07.509996, iter: 33, lr: [0.00043042] 'loss_bbox': 0.472, 'loss': 1.719, 'loss_cls': 1.22, time: 187.168
python op time: 44.8940899372
2019-08-13 07:04:53.089209, iter: 34, lr: [0.00043083] 'loss_bbox': 0.47, 'loss': 1.713, 'loss_cls': 1.22, time: 45.521
python op time: 217.416847944
2019-08-13 07:08:31.400332, iter: 35, lr: [0.00043125] 'loss_bbox': 0.47, 'loss': 1.696, 'loss_cls': 1.213, time: 218.257
python op time: 25.6316459179
2019-08-13 07:08:57.723419, iter: 36, lr: [0.00043167] 'loss_bbox': 0.469, 'loss': 1.713, 'loss_cls': 1.22, time: 26.265
python op time: 280.788195133
2019-08-13 07:13:39.299060, iter: 37, lr: [0.00043208] 'loss_bbox': 0.469, 'loss': 1.696, 'loss_cls': 1.213, time: 281.496
python op time: 23.1214470863
2019-08-13 07:14:03.323211, iter: 38, lr: [0.0004325] 'loss_bbox': 0.467, 'loss': 1.696, 'loss_cls': 1.213, time: 23.967
python op time: 144.426644087
2019-08-13 07:16:28.475675, iter: 39, lr: [0.00043292] 'loss_bbox': 0.468, 'loss': 1.696, 'loss_cls': 1.213, time: 145.100
python op time: 75.0952720642
2019-08-13 07:17:44.177109, iter: 40, lr: [0.00043333] 'loss_bbox': 0.47, 'loss': 1.681, 'loss_cls': 1.202, time: 75.649
python op time: 99.3657610416
2019-08-13 07:19:24.213570, iter: 41, lr: [0.00043375] 'loss_bbox': 0.47, 'loss': 1.681, 'loss_cls': 1.202, time: 99.977
python op time: 203.434242964
2019-08-13 07:22:48.347802, iter: 42, lr: [0.00043417] 'loss_bbox': 0.471, 'loss': 1.681, 'loss_cls': 1.202, time: 204.059
python op time: 61.9394979477
2019-08-13 07:23:51.121069, iter: 43, lr: [0.00043458] 'loss_bbox': 0.471, 'loss': 1.681, 'loss_cls': 1.202, time: 62.712
python op time: 31.1520681381
2019-08-13 07:24:22.943103, iter: 44, lr: [0.000435] 'loss_bbox': 0.471, 'loss': 1.694, 'loss_cls': 1.202, time: 31.758
python op time: 74.9583199024
2019-08-13 07:25:38.615426, iter: 45, lr: [0.00043542] 'loss_bbox': 0.47, 'loss': 1.676, 'loss_cls': 1.208, time: 75.625
python op time: 105.396972179
2019-08-13 07:27:24.654879, iter: 46, lr: [0.00043583] 'loss_bbox': 0.471, 'loss': 1.676, 'loss_cls': 1.206, time: 105.985
python op time: 22.8318169117
2019-08-13 07:27:48.088164, iter: 47, lr: [0.00043625] 'loss_bbox': 0.47, 'loss': 1.676, 'loss_cls': 1.206, time: 23.382
python op time: 117.881499052
2019-08-13 07:29:46.628132, iter: 48, lr: [0.00043667] 'loss_bbox': 0.469, 'loss': 1.669, 'loss_cls': 1.201, time: 118.480
python op time: 101.494047165
2019-08-13 07:31:29.028560, iter: 49, lr: [0.00043708] 'loss_bbox': 0.47, 'loss': 1.676, 'loss_cls': 1.206, time: 102.342
python op time: 33.2369048595
2019-08-13 07:32:02.936770, iter: 50, lr: [0.0004375] 'loss_bbox': 0.469, 'loss': 1.678, 'loss_cls': 1.207, time: 33.856
python op time: 82.4660539627
2019-08-13 07:33:26.084115, iter: 51, lr: [0.00043792] 'loss_bbox': 0.47, 'loss': 1.678, 'loss_cls': 1.207, time: 83.086
python op time: 192.154179096
2019-08-13 07:36:38.915167, iter: 52, lr: [0.00043833] 'loss_bbox': 0.47, 'loss': 1.678, 'loss_cls': 1.207, time: 192.773
python op time: 94.1463940144
2019-08-13 07:38:13.724444, iter: 53, lr: [0.00043875] 'loss_bbox': 0.469, 'loss': 1.678, 'loss_cls': 1.207, time: 94.750
python op time: 53.8623919487
2019-08-13 07:39:08.225024, iter: 54, lr: [0.00043917] 'loss_bbox': 0.47, 'loss': 1.673, 'loss_cls': 1.2, time: 54.442
python op time: 21.9032008648
2019-08-13 07:39:30.829246, iter: 55, lr: [0.00043958] 'loss_bbox': 0.473, 'loss': 1.678, 'loss_cls': 1.207, time: 22.562
python op time: 53.8026971817
2019-08-13 07:40:25.284083, iter: 56, lr: [0.00044] 'loss_bbox': 0.472, 'loss': 1.673, 'loss_cls': 1.2, time: 54.392
python op time: 55.4820208549
2019-08-13 07:41:21.560831, iter: 57, lr: [0.00044042] 'loss_bbox': 0.469, 'loss': 1.678, 'loss_cls': 1.207, time: 56.217
python op time: 44.5301988125
2019-08-13 07:42:06.988161, iter: 58, lr: [0.00044083] 'loss_bbox': 0.472, 'loss': 1.678, 'loss_cls': 1.207, time: 45.379
python op time: 12.709736824
2019-08-13 07:42:20.300919, iter: 59, lr: [0.00044125] 'loss_bbox': 0.472, 'loss': 1.697, 'loss_cls': 1.212, time: 13.267
python op time: 335.243394136
2019-08-13 07:47:56.379254, iter: 60, lr: [0.00044167] 'loss_bbox': 0.469, 'loss': 1.697, 'loss_cls': 1.212, time: 336.015
python op time: 107.058254004
2019-08-13 07:49:44.103388, iter: 61, lr: [0.00044208] 'loss_bbox': 0.466, 'loss': 1.678, 'loss_cls': 1.207, time: 107.664
python op time: 59.481441021
2019-08-13 07:50:44.336444, iter: 62, lr: [0.0004425] 'loss_bbox': 0.458, 'loss': 1.678, 'loss_cls': 1.207, time: 60.166
python op time: 114.028471947
2019-08-13 07:52:39.029801, iter: 63, lr: [0.00044292] 'loss_bbox': 0.458, 'loss': 1.669, 'loss_cls': 1.206, time: 114.633
python op time: 198.993797064
2019-08-13 07:55:58.820899, iter: 64, lr: [0.00044333] 'loss_bbox': 0.466, 'loss': 1.663, 'loss_cls': 1.2, time: 199.726
python op time: 73.6749720573
2019-08-13 07:57:13.330542, iter: 65, lr: [0.00044375] 'loss_bbox': 0.469, 'loss': 1.669, 'loss_cls': 1.2, time: 74.454
