W0813 03:54:04.621598 40626 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 9.0
W0813 03:54:04.625946 40626 device_context.cc:269] device: 0, cuDNN Version: 7.2.
W0813 03:56:30.304533 40626 system_allocator.cc:121] Cannot malloc 154 MB GPU memory. Please shrink FLAGS_fraction_of_gpu_memory_to_use or FLAGS_initial_gpu_memory_in_mb or FLAGS_reallocate_gpu_memory_in_mbenvironment variable to a lower value. Current FLAGS_fraction_of_gpu_memory_to_use value is 0.92. Current FLAGS_initial_gpu_memory_in_mb value is 0. Current FLAGS_reallocate_gpu_memory_in_mb value is 0
F0813 03:56:30.305279 40626 naive_best_fit_allocator.cc:164] Cannot allocate 154.000000MB in GPU 0, available 57.062500MB, total 22.381897GB, GpuMinChunkSize 256.000000B, GpuMaxChunkSize 2.218340GB, GPU memory used: 1.960926GB
*** Check failure stack trace: ***
    @     0x7ff6a018477d  google::LogMessage::Fail()
    @     0x7ff6a018822c  google::LogMessage::SendToLog()
    @     0x7ff6a01842a3  google::LogMessage::Flush()
    @     0x7ff6a018973e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7ff6a21be940  paddle::memory::legacy::Alloc<>()
    @     0x7ff6a21bedf5  paddle::memory::allocation::NaiveBestFitAllocator::AllocateImpl()
    @     0x7ff6a21b8ff3  paddle::memory::allocation::AllocatorFacade::Alloc()
    @     0x7ff6a21b92ae  paddle::memory::allocation::AllocatorFacade::AllocShared()
    @     0x7ff6a1db1a3c  paddle::memory::AllocShared()
    @     0x7ff6a218da14  paddle::framework::Tensor::mutable_data()
    @     0x7ff6a0042a97  paddle::framework::Tensor::mutable_data<>()
    @     0x7ff6a0cd22f8  paddle::operators::CUDNNConvOpKernel<>::Compute()
    @     0x7ff6a0cd2e33  _ZNSt17_Function_handlerIFvRKN6paddle9framework16ExecutionContextEEZNKS1_24OpKernelRegistrarFunctorINS0_8platform9CUDAPlaceELb0ELm0EJNS0_9operators17CUDNNConvOpKernelIfEENSA_IdEENSA_INS7_7float16EEEEEclEPKcSH_iEUlS4_E_E9_M_invokeERKSt9_Any_dataS4_
    @     0x7ff6a024cf60  paddle::imperative::Tracer::Trace()
    @     0x7ff6a0122705  _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind14BindImperativeEPNS_6moduleEEUlRNS2_10imperative6TracerEPNS6_6OpBaseERKSt13unordered_mapISsNS_6handleESt4hashISsESt8equal_toISsESaISt4pairIKSsSC_EEESN_SB_ISsN5boost7variantINSO_5blankEifSsSt6vectorIiSaIiEESR_IfSaIfEESR_ISsSaISsEEbSR_IbSaIbEEPNS2_9framework9BlockDescElSR_IS12_SaIS12_EESR_IlSaIlEENSO_6detail7variant5void_ES19_S19_S19_S19_S19_S19_EESE_SG_SaISH_ISI_S1A_EEENS2_8platform9CUDAPlaceEbE16_vIS8_SA_SN_SN_S1D_S1F_bEINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES1X_
    @     0x7ff6a0064b4e  pybind11::cpp_function::dispatcher()
    @     0x7ff70c4b3ce8  PyEval_EvalFrameEx
    @     0x7ff70c4b637d  PyEval_EvalCodeEx
    @     0x7ff70c4b3d70  PyEval_EvalFrameEx
    @     0x7ff70c4b637d  PyEval_EvalCodeEx
    @     0x7ff70c4b3d70  PyEval_EvalFrameEx
    @     0x7ff70c4b637d  PyEval_EvalCodeEx
    @     0x7ff70c4b3d70  PyEval_EvalFrameEx
    @     0x7ff70c4b637d  PyEval_EvalCodeEx
    @     0x7ff70c42d830  (unknown)
    @     0x7ff70c3fbd33  PyObject_Call
    @     0x7ff70c4b10a2  PyEval_EvalFrameEx
    @     0x7ff70c4b637d  PyEval_EvalCodeEx
    @     0x7ff70c42d830  (unknown)
    @     0x7ff70c3fbd33  PyObject_Call
    @     0x7ff70c40a74d  (unknown)
    @     0x7ff70c3fbd33  PyObject_Call
-----------  Configuration Arguments -----------
batch_size_per_im: 512
class_num: 81
data_dir: dataset/coco
dataset: coco2017
draw_threshold: 0.8
enable_ce: False
im_per_batch: 2
image_path: dataset/coco/val2017
learning_rate: 0.00125
log_window: 20
max_iter: 720000
max_size: 1333
model_save_dir: output
nms_thresh: 0.5
num_gpus: 1
padding_minibatch: False
pixel_means: [102.9801, 115.9465, 122.7717]
pretrained_model: imagenet_resnet50_fusebn
scales: [800]
score_thresh: 0.05
snapshot_stride: 40000
use_data_parallel: 0
use_flipped: True
use_gpu: True
------------------------------------------------
No optimizer loaded. If you didn't save optimizer, please ignore this. The program can still work with new optimizer. 
loading annotations into memory...
Done (t=31.50s)
creating index...
index created!
_add_gt_annotations took 43.864s
Appending horizontally-flipped training examples...
Loaded dataset: coco2017
236574 roidb entries
Filtered 2042 roidb entries: 236574 -> 234532
train on coco2017 with 236574 roidbs
loading annotations into memory...
Done (t=1.45s)
creating index...
index created!
Loaded dataset: coco2017
5000 roidb entries
val on coco2017 with 5000 roidbs
W0813 03:59:04.957798 40785 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 9.0
W0813 03:59:04.962654 40785 device_context.cc:269] device: 0, cuDNN Version: 7.2.
-----------  Configuration Arguments -----------
batch_size_per_im: 512
class_num: 81
data_dir: dataset/coco
dataset: coco2017
draw_threshold: 0.8
enable_ce: False
im_per_batch: 2
image_path: dataset/coco/val2017
learning_rate: 0.00125
log_window: 20
max_iter: 720000
max_size: 1333
model_save_dir: output
nms_thresh: 0.5
num_gpus: 1
padding_minibatch: False
pixel_means: [102.9801, 115.9465, 122.7717]
pretrained_model: imagenet_resnet50_fusebn
scales: [800]
score_thresh: 0.05
snapshot_stride: 40000
use_data_parallel: 0
use_flipped: True
use_gpu: True
------------------------------------------------
No optimizer loaded. If you didn't save optimizer, please ignore this. The program can still work with new optimizer. 
loading annotations into memory...
Done (t=32.30s)
creating index...
index created!
_add_gt_annotations took 43.017s
Appending horizontally-flipped training examples...
Loaded dataset: coco2017
236574 roidb entries
Filtered 2042 roidb entries: 236574 -> 234532
train on coco2017 with 236574 roidbs
loading annotations into memory...
Done (t=1.47s)
creating index...
index created!
Loaded dataset: coco2017
5000 roidb entries
val on coco2017 with 5000 roidbs
2019-08-13 04:02:35.880157, iter: 0, lr: [0.00041667] 'loss_bbox': 0.474, 'loss': 1.622, 'loss_cls': 1.148, time: 0.198
2019-08-13 04:03:07.593938, iter: 1, lr: [0.00041708] 'loss_bbox': 0.473, 'loss': 1.69, 'loss_cls': 1.217, time: 66.618
2019-08-13 04:06:38.924352, iter: 2, lr: [0.0004175] 'loss_bbox': 0.474, 'loss': 1.625, 'loss_cls': 1.15, time: 31.718
2019-08-13 04:10:21.236692, iter: 3, lr: [0.00041792] 'loss_bbox': 0.473, 'loss': 1.624, 'loss_cls': 1.153, time: 211.330
2019-08-13 04:11:02.249177, iter: 4, lr: [0.00041833] 'loss_bbox': 0.472, 'loss': 1.625, 'loss_cls': 1.155, time: 222.305
2019-08-13 04:12:14.108693, iter: 5, lr: [0.00041875] 'loss_bbox': 0.471, 'loss': 1.624, 'loss_cls': 1.153, time: 41.015
2019-08-13 04:13:23.310044, iter: 6, lr: [0.00041917] 'loss_bbox': 0.471, 'loss': 1.622, 'loss_cls': 1.15, time: 71.860
2019-08-13 04:15:28.109659, iter: 7, lr: [0.00041958] 'loss_bbox': 0.471, 'loss': 1.624, 'loss_cls': 1.153, time: 69.201
2019-08-13 04:16:17.285096, iter: 8, lr: [0.00042] 'loss_bbox': 0.471, 'loss': 1.625, 'loss_cls': 1.155, time: 124.795
2019-08-13 04:18:19.557937, iter: 9, lr: [0.00042042] 'loss_bbox': 0.471, 'loss': 1.643, 'loss_cls': 1.162, time: 49.181
2019-08-13 04:18:39.908997, iter: 10, lr: [0.00042083] 'loss_bbox': 0.472, 'loss': 1.66, 'loss_cls': 1.168, time: 122.272
2019-08-13 04:21:38.420690, iter: 11, lr: [0.00042125] 'loss_bbox': 0.471, 'loss': 1.643, 'loss_cls': 1.162, time: 20.352
2019-08-13 04:23:47.957697, iter: 12, lr: [0.00042167] 'loss_bbox': 0.472, 'loss': 1.645, 'loss_cls': 1.168, time: 178.513
2019-08-13 04:27:52.581749, iter: 13, lr: [0.00042208] 'loss_bbox': 0.471, 'loss': 1.635, 'loss_cls': 1.162, time: 129.531
2019-08-13 04:28:41.853009, iter: 14, lr: [0.0004225] 'loss_bbox': 0.472, 'loss': 1.645, 'loss_cls': 1.168, time: 244.627
2019-08-13 04:30:33.572138, iter: 15, lr: [0.00042292] 'loss_bbox': 0.471, 'loss': 1.635, 'loss_cls': 1.162, time: 49.268
2019-08-13 04:32:27.392117, iter: 16, lr: [0.00042333] 'loss_bbox': 0.472, 'loss': 1.645, 'loss_cls': 1.168, time: 111.723
2019-08-13 04:34:36.975083, iter: 17, lr: [0.00042375] 'loss_bbox': 0.473, 'loss': 1.652, 'loss_cls': 1.169, time: 113.818
2019-08-13 04:34:57.358317, iter: 18, lr: [0.00042417] 'loss_bbox': 0.472, 'loss': 1.66, 'loss_cls': 1.17, time: 129.598
2019-08-13 04:35:51.034376, iter: 19, lr: [0.00042458] 'loss_bbox': 0.473, 'loss': 1.664, 'loss_cls': 1.191, time: 20.368
2019-08-13 04:37:20.295829, iter: 20, lr: [0.000425] 'loss_bbox': 0.471, 'loss': 1.664, 'loss_cls': 1.204, time: 53.677
2019-08-13 04:40:16.854377, iter: 21, lr: [0.00042542] 'loss_bbox': 0.468, 'loss': 1.658, 'loss_cls': 1.183, time: 89.248
2019-08-13 04:42:03.900248, iter: 22, lr: [0.00042583] 'loss_bbox': 0.468, 'loss': 1.658, 'loss_cls': 1.183, time: 176.570
2019-08-13 04:43:21.945291, iter: 23, lr: [0.00042625] 'loss_bbox': 0.469, 'loss': 1.662, 'loss_cls': 1.197, time: 107.042
2019-08-13 04:44:37.451644, iter: 24, lr: [0.00042667] 'loss_bbox': 0.467, 'loss': 1.658, 'loss_cls': 1.185, time: 78.047
2019-08-13 04:45:01.071483, iter: 25, lr: [0.00042708] 'loss_bbox': 0.467, 'loss': 1.662, 'loss_cls': 1.197, time: 75.500
2019-08-13 04:45:27.370566, iter: 26, lr: [0.0004275] 'loss_bbox': 0.471, 'loss': 1.666, 'loss_cls': 1.204, time: 23.626
2019-08-13 04:46:45.202736, iter: 27, lr: [0.00042792] 'loss_bbox': 0.467, 'loss': 1.666, 'loss_cls': 1.204, time: 26.302
2019-08-13 04:48:12.083710, iter: 28, lr: [0.00042833] 'loss_bbox': 0.471, 'loss': 1.703, 'loss_cls': 1.204, time: 77.829
2019-08-13 04:48:53.240279, iter: 29, lr: [0.00042875] 'loss_bbox': 0.471, 'loss': 1.703, 'loss_cls': 1.204, time: 86.873
2019-08-13 04:49:22.246493, iter: 30, lr: [0.00042917] 'loss_bbox': 0.471, 'loss': 1.703, 'loss_cls': 1.204, time: 41.167
2019-08-13 04:51:37.200997, iter: 31, lr: [0.00042958] 'loss_bbox': 0.473, 'loss': 1.703, 'loss_cls': 1.204, time: 29.010
2019-08-13 04:52:20.735971, iter: 32, lr: [0.00043] 'loss_bbox': 0.47, 'loss': 1.723, 'loss_cls': 1.231, time: 134.947
2019-08-13 04:53:38.722189, iter: 33, lr: [0.00043042] 'loss_bbox': 0.47, 'loss': 1.723, 'loss_cls': 1.236, time: 43.536
2019-08-13 04:54:02.294115, iter: 34, lr: [0.00043083] 'loss_bbox': 0.47, 'loss': 1.723, 'loss_cls': 1.236, time: 78.000
2019-08-13 04:54:56.890482, iter: 35, lr: [0.00043125] 'loss_bbox': 0.474, 'loss': 1.723, 'loss_cls': 1.236, time: 23.561
2019-08-13 04:55:34.621964, iter: 36, lr: [0.00043167] 'loss_bbox': 0.474, 'loss': 1.723, 'loss_cls': 1.236, time: 54.625
2019-08-13 04:57:19.542538, iter: 37, lr: [0.00043208] 'loss_bbox': 0.47, 'loss': 1.702, 'loss_cls': 1.236, time: 37.705
2019-08-13 05:02:13.838490, iter: 38, lr: [0.0004325] 'loss_bbox': 0.472, 'loss': 1.689, 'loss_cls': 1.214, time: 104.924
2019-08-13 05:02:29.887506, iter: 39, lr: [0.00043292] 'loss_bbox': 0.472, 'loss': 1.689, 'loss_cls': 1.214, time: 294.285
2019-08-13 05:04:59.000400, iter: 40, lr: [0.00043333] 'loss_bbox': 0.475, 'loss': 1.696, 'loss_cls': 1.214, time: 16.049
2019-08-13 05:07:09.260919, iter: 41, lr: [0.00043375] 'loss_bbox': 0.48, 'loss': 1.702, 'loss_cls': 1.214, time: 149.119
2019-08-13 05:07:52.637094, iter: 42, lr: [0.00043417] 'loss_bbox': 0.475, 'loss': 1.708, 'loss_cls': 1.236, time: 130.260
2019-08-13 05:08:31.655608, iter: 43, lr: [0.00043458] 'loss_bbox': 0.475, 'loss': 1.716, 'loss_cls': 1.251, time: 43.387
2019-08-13 05:09:08.329582, iter: 44, lr: [0.000435] 'loss_bbox': 0.475, 'loss': 1.722, 'loss_cls': 1.254, time: 39.021
2019-08-13 05:10:18.473999, iter: 45, lr: [0.00043542] 'loss_bbox': 0.475, 'loss': 1.716, 'loss_cls': 1.251, time: 36.663
2019-08-13 05:12:32.074000, iter: 46, lr: [0.00043583] 'loss_bbox': 0.475, 'loss': 1.708, 'loss_cls': 1.236, time: 70.148
2019-08-13 05:15:15.274173, iter: 47, lr: [0.00043625] 'loss_bbox': 0.475, 'loss': 1.708, 'loss_cls': 1.236, time: 133.601
2019-08-13 05:17:43.632479, iter: 48, lr: [0.00043667] 'loss_bbox': 0.472, 'loss': 1.702, 'loss_cls': 1.214, time: 163.185
2019-08-13 05:20:24.676039, iter: 49, lr: [0.00043708] 'loss_bbox': 0.471, 'loss': 1.696, 'loss_cls': 1.198, time: 148.366
2019-08-13 05:21:26.155130, iter: 50, lr: [0.0004375] 'loss_bbox': 0.47, 'loss': 1.696, 'loss_cls': 1.198, time: 161.045
2019-08-13 05:21:46.497456, iter: 51, lr: [0.00043792] 'loss_bbox': 0.469, 'loss': 1.702, 'loss_cls': 1.214, time: 61.480
2019-08-13 05:22:29.994053, iter: 52, lr: [0.00043833] 'loss_bbox': 0.469, 'loss': 1.704, 'loss_cls': 1.214, time: 20.339
2019-08-13 05:25:02.833749, iter: 53, lr: [0.00043875] 'loss_bbox': 0.469, 'loss': 1.704, 'loss_cls': 1.198, time: 43.506
2019-08-13 05:25:28.990157, iter: 54, lr: [0.00043917] 'loss_bbox': 0.467, 'loss': 1.704, 'loss_cls': 1.198, time: 152.836
2019-08-13 05:29:11.771409, iter: 55, lr: [0.00043958] 'loss_bbox': 0.467, 'loss': 1.702, 'loss_cls': 1.187, time: 26.155
2019-08-13 05:29:43.560090, iter: 56, lr: [0.00044] 'loss_bbox': 0.466, 'loss': 1.702, 'loss_cls': 1.187, time: 222.784
2019-08-13 05:30:55.763741, iter: 57, lr: [0.00044042] 'loss_bbox': 0.465, 'loss': 1.702, 'loss_cls': 1.196, time: 31.781
2019-08-13 05:33:04.930226, iter: 58, lr: [0.00044083] 'loss_bbox': 0.464, 'loss': 1.702, 'loss_cls': 1.196, time: 72.195
2019-08-13 05:33:25.342159, iter: 59, lr: [0.00044125] 'loss_bbox': 0.463, 'loss': 1.702, 'loss_cls': 1.196, time: 129.176
2019-08-13 05:33:48.797247, iter: 60, lr: [0.00044167] 'loss_bbox': 0.463, 'loss': 1.713, 'loss_cls': 1.228, time: 20.405
2019-08-13 05:34:32.028517, iter: 61, lr: [0.00044208] 'loss_bbox': 0.463, 'loss': 1.713, 'loss_cls': 1.242, time: 23.452
2019-08-13 05:35:00.649281, iter: 62, lr: [0.0004425] 'loss_bbox': 0.463, 'loss': 1.713, 'loss_cls': 1.244, time: 43.240
2019-08-13 05:36:04.082478, iter: 63, lr: [0.00044292] 'loss_bbox': 0.461, 'loss': 1.693, 'loss_cls': 1.218, time: 28.620
2019-08-13 05:36:53.022722, iter: 64, lr: [0.00044333] 'loss_bbox': 0.463, 'loss': 1.693, 'loss_cls': 1.218, time: 63.437
2019-08-13 05:39:51.320369, iter: 65, lr: [0.00044375] 'loss_bbox': 0.464, 'loss': 1.693, 'loss_cls': 1.218, time: 48.933
2019-08-13 05:40:23.384594, iter: 66, lr: [0.00044417] 'loss_bbox': 0.463, 'loss': 1.703, 'loss_cls': 1.24, time: 178.303
2019-08-13 05:41:02.532459, iter: 67, lr: [0.00044458] 'loss_bbox': 0.463, 'loss': 1.713, 'loss_cls': 1.245, time: 32.054
2019-08-13 05:44:11.145004, iter: 68, lr: [0.000445] 'loss_bbox': 0.463, 'loss': 1.713, 'loss_cls': 1.245, time: 39.158
2019-08-13 05:47:06.628357, iter: 69, lr: [0.00044542] 'loss_bbox': 0.464, 'loss': 1.713, 'loss_cls': 1.245, time: 188.616
2019-08-13 05:47:51.396222, iter: 70, lr: [0.00044583] 'loss_bbox': 0.466, 'loss': 1.703, 'loss_cls': 1.238, time: 175.500
2019-08-13 05:50:53.117297, iter: 71, lr: [0.00044625] 'loss_bbox': 0.464, 'loss': 1.687, 'loss_cls': 1.221, time: 44.758
2019-08-13 05:51:34.382835, iter: 72, lr: [0.00044667] 'loss_bbox': 0.464, 'loss': 1.687, 'loss_cls': 1.221, time: 181.715
2019-08-13 05:51:49.176507, iter: 73, lr: [0.00044708] 'loss_bbox': 0.465, 'loss': 1.703, 'loss_cls': 1.238, time: 41.266
2019-08-13 05:52:32.957039, iter: 74, lr: [0.0004475] 'loss_bbox': 0.465, 'loss': 1.687, 'loss_cls': 1.221, time: 14.783
2019-08-13 05:54:30.767526, iter: 75, lr: [0.00044792] 'loss_bbox': 0.461, 'loss': 1.687, 'loss_cls': 1.221, time: 43.787
2019-08-13 05:57:56.988991, iter: 76, lr: [0.00044833] 'loss_bbox': 0.459, 'loss': 1.672, 'loss_cls': 1.207, time: 117.812
2019-08-13 05:58:53.093076, iter: 77, lr: [0.00044875] 'loss_bbox': 0.462, 'loss': 1.687, 'loss_cls': 1.211, time: 206.233
2019-08-13 06:00:10.504903, iter: 78, lr: [0.00044917] 'loss_bbox': 0.462, 'loss': 1.699, 'loss_cls': 1.222, time: 56.100
2019-08-13 06:01:20.670994, iter: 79, lr: [0.00044958] 'loss_bbox': 0.462, 'loss': 1.687, 'loss_cls': 1.211, time: 77.411
2019-08-13 06:02:05.215940, iter: 80, lr: [0.00045] 'loss_bbox': 0.459, 'loss': 1.687, 'loss_cls': 1.211, time: 70.162
2019-08-13 06:03:06.142936, iter: 81, lr: [0.00045042] 'loss_bbox': 0.452, 'loss': 1.671, 'loss_cls': 1.211, time: 44.541
2019-08-13 06:03:55.486553, iter: 82, lr: [0.00045083] 'loss_bbox': 0.447, 'loss': 1.655, 'loss_cls': 1.202, time: 60.933
2019-08-13 06:06:06.698948, iter: 83, lr: [0.00045125] 'loss_bbox': 0.452, 'loss': 1.671, 'loss_cls': 1.211, time: 49.346
2019-08-13 06:06:39.552596, iter: 84, lr: [0.00045167] 'loss_bbox': 0.447, 'loss': 1.671, 'loss_cls': 1.211, time: 131.194
2019-08-13 06:08:46.664917, iter: 85, lr: [0.00045208] 'loss_bbox': 0.447, 'loss': 1.671, 'loss_cls': 1.211, time: 32.865
2019-08-13 06:09:58.876912, iter: 86, lr: [0.0004525] 'loss_bbox': 0.452, 'loss': 1.671, 'loss_cls': 1.203, time: 127.111
2019-08-13 06:11:40.750370, iter: 87, lr: [0.00045292] 'loss_bbox': 0.452, 'loss': 1.662, 'loss_cls': 1.194, time: 72.215
2019-08-13 06:12:31.255020, iter: 88, lr: [0.00045333] 'loss_bbox': 0.459, 'loss': 1.671, 'loss_cls': 1.203, time: 101.887
2019-08-13 06:13:14.868066, iter: 89, lr: [0.00045375] 'loss_bbox': 0.452, 'loss': 1.672, 'loss_cls': 1.211, time: 50.489
2019-08-13 06:13:52.683091, iter: 90, lr: [0.00045417] 'loss_bbox': 0.452, 'loss': 1.673, 'loss_cls': 1.212, time: 43.614
2019-08-13 06:15:51.359221, iter: 91, lr: [0.00045458] 'loss_bbox': 0.458, 'loss': 1.673, 'loss_cls': 1.212, time: 37.836
2019-08-13 06:16:48.109368, iter: 92, lr: [0.000455] 'loss_bbox': 0.458, 'loss': 1.67, 'loss_cls': 1.212, time: 118.663
2019-08-13 06:17:42.820735, iter: 93, lr: [0.00045542] 'loss_bbox': 0.458, 'loss': 1.666, 'loss_cls': 1.203, time: 56.754
2019-08-13 06:22:50.820880, iter: 94, lr: [0.00045583] 'loss_bbox': 0.459, 'loss': 1.666, 'loss_cls': 1.203, time: 54.710
2019-08-13 06:23:11.155593, iter: 95, lr: [0.00045625] 'loss_bbox': 0.462, 'loss': 1.671, 'loss_cls': 1.212, time: 307.989
2019-08-13 06:24:16.366282, iter: 96, lr: [0.00045667] 'loss_bbox': 0.462, 'loss': 1.671, 'loss_cls': 1.212, time: 20.345
2019-08-13 06:25:10.184021, iter: 97, lr: [0.00045708] 'loss_bbox': 0.459, 'loss': 1.666, 'loss_cls': 1.212, time: 65.218
2019-08-13 06:26:43.345165, iter: 98, lr: [0.0004575] 'loss_bbox': 0.459, 'loss': 1.666, 'loss_cls': 1.212, time: 53.805
2019-08-13 06:30:14.783881, iter: 99, lr: [0.00045792] 'loss_bbox': 0.459, 'loss': 1.666, 'loss_cls': 1.212, time: 93.162
2019-08-13 06:30:56.763453, iter: 100, lr: [0.00045833] 'loss_bbox': 0.457, 'loss': 1.666, 'loss_cls': 1.212, time: 211.441
2019-08-13 06:32:57.492683, iter: 101, lr: [0.00045875] 'loss_bbox': 0.46, 'loss': 1.666, 'loss_cls': 1.204, time: 42.004
2019-08-13 06:35:14.199558, iter: 102, lr: [0.00045917] 'loss_bbox': 0.46, 'loss': 1.666, 'loss_cls': 1.204, time: 120.708
2019-08-13 06:35:51.802276, iter: 103, lr: [0.00045958] 'loss_bbox': 0.46, 'loss': 1.666, 'loss_cls': 1.208, time: 136.703
2019-08-13 06:36:47.606466, iter: 104, lr: [0.00046] 'loss_bbox': 0.46, 'loss': 1.666, 'loss_cls': 1.208, time: 37.611
2019-08-13 06:39:32.971863, iter: 105, lr: [0.00046042] 'loss_bbox': 0.46, 'loss': 1.666, 'loss_cls': 1.208, time: 55.793
2019-08-13 06:42:29.079246, iter: 106, lr: [0.00046083] 'loss_bbox': 0.459, 'loss': 1.666, 'loss_cls': 1.218, time: 165.365
2019-08-13 06:45:32.735793, iter: 107, lr: [0.00046125] 'loss_bbox': 0.459, 'loss': 1.667, 'loss_cls': 1.218, time: 176.098
2019-08-13 06:48:09.740954, iter: 108, lr: [0.00046167] 'loss_bbox': 0.459, 'loss': 1.666, 'loss_cls': 1.206, time: 183.669
2019-08-13 06:48:56.497161, iter: 109, lr: [0.00046208] 'loss_bbox': 0.459, 'loss': 1.667, 'loss_cls': 1.206, time: 157.003
2019-08-13 06:49:26.853857, iter: 110, lr: [0.0004625] 'loss_bbox': 0.457, 'loss': 1.667, 'loss_cls': 1.206, time: 46.760
2019-08-13 06:50:44.407963, iter: 111, lr: [0.00046292] 'loss_bbox': 0.457, 'loss': 1.671, 'loss_cls': 1.214, time: 30.364
2019-08-13 06:52:30.545403, iter: 112, lr: [0.00046333] 'loss_bbox': 0.457, 'loss': 1.667, 'loss_cls': 1.203, time: 77.540
2019-08-13 06:54:45.485898, iter: 113, lr: [0.00046375] 'loss_bbox': 0.456, 'loss': 1.659, 'loss_cls': 1.196, time: 106.137
2019-08-13 06:55:08.920841, iter: 114, lr: [0.00046417] 'loss_bbox': 0.457, 'loss': 1.67, 'loss_cls': 1.214, time: 134.945
2019-08-13 06:55:32.293916, iter: 115, lr: [0.00046458] 'loss_bbox': 0.455, 'loss': 1.67, 'loss_cls': 1.214, time: 23.439
2019-08-13 06:56:01.088145, iter: 116, lr: [0.000465] 'loss_bbox': 0.455, 'loss': 1.675, 'loss_cls': 1.218, time: 23.370
2019-08-13 06:58:50.862328, iter: 117, lr: [0.00046542] 'loss_bbox': 0.455, 'loss': 1.675, 'loss_cls': 1.214, time: 28.789
2019-08-13 07:00:44.542049, iter: 118, lr: [0.00046583] 'loss_bbox': 0.455, 'loss': 1.677, 'loss_cls': 1.214, time: 169.775
2019-08-13 07:01:22.158751, iter: 119, lr: [0.00046625] 'loss_bbox': 0.454, 'loss': 1.677, 'loss_cls': 1.218, time: 113.682
2019-08-13 07:02:41.167234, iter: 120, lr: [0.00046667] 'loss_bbox': 0.454, 'loss': 1.675, 'loss_cls': 1.214, time: 37.620
2019-08-13 07:02:54.421282, iter: 121, lr: [0.00046708] 'loss_bbox': 0.45, 'loss': 1.679, 'loss_cls': 1.218, time: 79.011
2019-08-13 07:04:25.521936, iter: 122, lr: [0.0004675] 'loss_bbox': 0.454, 'loss': 1.679, 'loss_cls': 1.218, time: 13.258
2019-08-13 07:06:58.060383, iter: 123, lr: [0.00046792] 'loss_bbox': 0.454, 'loss': 1.675, 'loss_cls': 1.214, time: 91.092
2019-08-13 07:07:24.531419, iter: 124, lr: [0.00046833] 'loss_bbox': 0.454, 'loss': 1.675, 'loss_cls': 1.214, time: 152.546
2019-08-13 07:09:08.827979, iter: 125, lr: [0.00046875] 'loss_bbox': 0.45, 'loss': 1.675, 'loss_cls': 1.218, time: 26.463
2019-08-13 07:10:12.841539, iter: 126, lr: [0.00046917] 'loss_bbox': 0.449, 'loss': 1.674, 'loss_cls': 1.216, time: 104.277
2019-08-13 07:14:33.065391, iter: 127, lr: [0.00046958] 'loss_bbox': 0.448, 'loss': 1.67, 'loss_cls': 1.216, time: 64.039
2019-08-13 07:15:07.078597, iter: 128, lr: [0.00047] 'loss_bbox': 0.444, 'loss': 1.67, 'loss_cls': 1.216, time: 260.221
2019-08-13 07:17:24.432151, iter: 129, lr: [0.00047042] 'loss_bbox': 0.444, 'loss': 1.667, 'loss_cls': 1.21, time: 34.015
2019-08-13 07:18:01.045580, iter: 130, lr: [0.00047083] 'loss_bbox': 0.444, 'loss': 1.667, 'loss_cls': 1.21, time: 137.356
2019-08-13 07:19:26.428821, iter: 131, lr: [0.00047125] 'loss_bbox': 0.444, 'loss': 1.667, 'loss_cls': 1.215, time: 36.623
2019-08-13 07:19:56.542266, iter: 132, lr: [0.00047167] 'loss_bbox': 0.444, 'loss': 1.67, 'loss_cls': 1.225, time: 85.374
2019-08-13 07:20:46.015569, iter: 133, lr: [0.00047208] 'loss_bbox': 0.444, 'loss': 1.67, 'loss_cls': 1.226, time: 30.115
2019-08-13 07:21:21.361518, iter: 134, lr: [0.0004725] 'loss_bbox': 0.444, 'loss': 1.67, 'loss_cls': 1.226, time: 49.462
2019-08-13 07:21:59.182141, iter: 135, lr: [0.00047292] 'loss_bbox': 0.444, 'loss': 1.67, 'loss_cls': 1.226, time: 35.358
2019-08-13 07:23:11.435014, iter: 136, lr: [0.00047333] 'loss_bbox': 0.444, 'loss': 1.67, 'loss_cls': 1.222, time: 37.812
2019-08-13 07:23:28.428835, iter: 137, lr: [0.00047375] 'loss_bbox': 0.444, 'loss': 1.686, 'loss_cls': 1.226, time: 72.259
2019-08-13 07:25:09.484937, iter: 138, lr: [0.00047417] 'loss_bbox': 0.444, 'loss': 1.678, 'loss_cls': 1.222, time: 16.986
2019-08-13 07:25:35.832351, iter: 139, lr: [0.00047458] 'loss_bbox': 0.442, 'loss': 1.697, 'loss_cls': 1.226, time: 101.062
2019-08-13 07:26:58.502583, iter: 140, lr: [0.000475] 'loss_bbox': 0.442, 'loss': 1.703, 'loss_cls': 1.226, time: 26.342
2019-08-13 07:27:13.158677, iter: 141, lr: [0.00047542] 'loss_bbox': 0.445, 'loss': 1.703, 'loss_cls': 1.226, time: 82.670
2019-08-13 07:29:29.290448, iter: 142, lr: [0.00047583] 'loss_bbox': 0.445, 'loss': 1.703, 'loss_cls': 1.226, time: 14.654
2019-08-13 07:30:47.494447, iter: 143, lr: [0.00047625] 'loss_bbox': 0.445, 'loss': 1.703, 'loss_cls': 1.226, time: 136.137
2019-08-13 07:31:07.926239, iter: 144, lr: [0.00047667] 'loss_bbox': 0.45, 'loss': 1.706, 'loss_cls': 1.226, time: 78.205
2019-08-13 07:31:40.021381, iter: 145, lr: [0.00047708] 'loss_bbox': 0.45, 'loss': 1.724, 'loss_cls': 1.231, time: 20.438
2019-08-13 07:33:50.312959, iter: 146, lr: [0.0004775] 'loss_bbox': 0.45, 'loss': 1.724, 'loss_cls': 1.231, time: 32.088
2019-08-13 07:34:06.665515, iter: 147, lr: [0.00047792] 'loss_bbox': 0.45, 'loss': 1.735, 'loss_cls': 1.263, time: 130.292
2019-08-13 07:38:02.788349, iter: 148, lr: [0.00047833] 'loss_bbox': 0.452, 'loss': 1.735, 'loss_cls': 1.263, time: 16.347
2019-08-13 07:40:51.784114, iter: 149, lr: [0.00047875] 'loss_bbox': 0.452, 'loss': 1.735, 'loss_cls': 1.263, time: 236.146
2019-08-13 07:42:02.801441, iter: 150, lr: [0.00047917] 'loss_bbox': 0.453, 'loss': 1.735, 'loss_cls': 1.254, time: 168.984
2019-08-13 07:45:37.884215, iter: 151, lr: [0.00047958] 'loss_bbox': 0.453, 'loss': 1.724, 'loss_cls': 1.245, time: 71.025
2019-08-13 07:49:06.799169, iter: 152, lr: [0.00048] 'loss_bbox': 0.453, 'loss': 1.706, 'loss_cls': 1.222, time: 215.070
2019-08-13 07:50:01.504522, iter: 153, lr: [0.00048042] 'loss_bbox': 0.456, 'loss': 1.706, 'loss_cls': 1.222, time: 208.927
2019-08-13 07:51:58.477212, iter: 154, lr: [0.00048083] 'loss_bbox': 0.453, 'loss': 1.691, 'loss_cls': 1.21, time: 54.692
2019-08-13 07:52:35.867928, iter: 155, lr: [0.00048125] 'loss_bbox': 0.453, 'loss': 1.691, 'loss_cls': 1.21, time: 116.973
2019-08-13 07:54:01.944448, iter: 156, lr: [0.00048167] 'loss_bbox': 0.452, 'loss': 1.683, 'loss_cls': 1.195, time: 37.399
2019-08-13 07:55:34.579247, iter: 157, lr: [0.00048208] 'loss_bbox': 0.453, 'loss': 1.683, 'loss_cls': 1.195, time: 86.067
2019-08-13 07:57:46.294772, iter: 158, lr: [0.0004825] 'loss_bbox': 0.453, 'loss': 1.681, 'loss_cls': 1.2, time: 92.642
2019-08-13 08:01:50.748112, iter: 159, lr: [0.00048292] 'loss_bbox': 0.453, 'loss': 1.661, 'loss_cls': 1.194, time: 131.715
2019-08-13 08:03:08.959902, iter: 160, lr: [0.00048333] 'loss_bbox': 0.453, 'loss': 1.661, 'loss_cls': 1.195, time: 244.443
2019-08-13 08:05:20.550344, iter: 161, lr: [0.00048375] 'loss_bbox': 0.452, 'loss': 1.635, 'loss_cls': 1.186, time: 78.222
2019-08-13 08:07:04.773428, iter: 162, lr: [0.00048417] 'loss_bbox': 0.452, 'loss': 1.642, 'loss_cls': 1.189, time: 131.581
2019-08-13 08:07:18.016899, iter: 163, lr: [0.00048458] 'loss_bbox': 0.449, 'loss': 1.662, 'loss_cls': 1.195, time: 104.239
2019-08-13 08:08:40.866914, iter: 164, lr: [0.000485] 'loss_bbox': 0.449, 'loss': 1.662, 'loss_cls': 1.195, time: 13.239
2019-08-13 08:09:24.116133, iter: 165, lr: [0.00048542] 'loss_bbox': 0.452, 'loss': 1.662, 'loss_cls': 1.195, time: 82.838
2019-08-13 08:10:18.632180, iter: 166, lr: [0.00048583] 'loss_bbox': 0.456, 'loss': 1.672, 'loss_cls': 1.198, time: 43.252
2019-08-13 08:11:23.551938, iter: 167, lr: [0.00048625] 'loss_bbox': 0.459, 'loss': 1.653, 'loss_cls': 1.192, time: 54.514
2019-08-13 08:12:58.286036, iter: 168, lr: [0.00048667] 'loss_bbox': 0.459, 'loss': 1.653, 'loss_cls': 1.192, time: 64.913
2019-08-13 08:13:52.782862, iter: 169, lr: [0.00048708] 'loss_bbox': 0.46, 'loss': 1.658, 'loss_cls': 1.194, time: 94.743
2019-08-13 08:16:15.650813, iter: 170, lr: [0.0004875] 'loss_bbox': 0.459, 'loss': 1.648, 'loss_cls': 1.191, time: 54.496
2019-08-13 08:18:19.590945, iter: 171, lr: [0.00048792] 'loss_bbox': 0.457, 'loss': 1.648, 'loss_cls': 1.191, time: 142.862
2019-08-13 08:19:03.749714, iter: 172, lr: [0.00048833] 'loss_bbox': 0.459, 'loss': 1.658, 'loss_cls': 1.194, time: 123.945
2019-08-13 08:20:03.640244, iter: 173, lr: [0.00048875] 'loss_bbox': 0.458, 'loss': 1.658, 'loss_cls': 1.194, time: 44.161
2019-08-13 08:23:10.775502, iter: 174, lr: [0.00048917] 'loss_bbox': 0.458, 'loss': 1.658, 'loss_cls': 1.194, time: 59.895
2019-08-13 08:23:42.711345, iter: 175, lr: [0.00048958] 'loss_bbox': 0.455, 'loss': 1.658, 'loss_cls': 1.194, time: 187.133
2019-08-13 08:24:03.121458, iter: 176, lr: [0.00049] 'loss_bbox': 0.458, 'loss': 1.663, 'loss_cls': 1.198, time: 31.951
W0816 12:22:35.957337 50541 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 9.0
W0816 12:22:35.962046 50541 device_context.cc:269] device: 0, cuDNN Version: 7.2.
W0821 07:47:02.738185    24 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 9.0
W0821 07:47:02.888947    24 device_context.cc:269] device: 0, cuDNN Version: 7.2.
-----------  Configuration Arguments -----------
batch_size_per_im: 512
class_num: 81
data_dir: dataset/coco
dataset: coco2017
draw_threshold: 0.8
enable_ce: False
im_per_batch: 2
image_path: dataset/coco/val2017
learning_rate: 0.00125
log_window: 20
lr_steps: [480000, 640000]
max_iter: 720000
max_size: 1333
model_save_dir: output_bs2
nms_thresh: 0.5
num_gpus: 1
padding_minibatch: False
pixel_means: [102.9801, 115.9465, 122.7717]
pretrained_model: output_bs2/model_iter559999/
scales: [800]
score_thresh: 0.05
snapshot_iter: 10000
use_data_parallel: 0
use_flipped: True
use_gpu: True
warm_up_iter: 1000
------------------------------------------------
loading annotations into memory...
Done (t=31.53s)
creating index...
index created!
_add_gt_annotations took 45.400s
Appending horizontally-flipped training examples...
Loaded dataset: coco2017
236574 roidb entries
Filtered 2042 roidb entries: 236574 -> 234532
train on coco2017 with 236574 roidbs
loading annotations into memory...
Done (t=1.54s)
creating index...
index created!
Loaded dataset: coco2017
5000 roidb entries
val on coco2017 with 5000 roidbs
5441406.5
1098974.1
240502.64
60077.906
15165.779
Traceback (most recent call last):
  File "train.py", line 297, in <module>
    train()
  File "train.py", line 279, in train
    train_loop()
  File "train.py", line 211, in train_loop
    optimizer.minimize(loss)
AttributeError: 'dict' object has no attribute 'minimize'
W0821 07:52:22.949111    94 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 9.0
W0821 07:52:22.953933    94 device_context.cc:269] device: 0, cuDNN Version: 7.2.
-----------  Configuration Arguments -----------
batch_size_per_im: 512
class_num: 81
data_dir: dataset/coco
dataset: coco2017
draw_threshold: 0.8
enable_ce: False
im_per_batch: 2
image_path: dataset/coco/val2017
learning_rate: 0.00125
log_window: 20
lr_steps: [480000, 640000]
max_iter: 720000
max_size: 1333
model_save_dir: output_bs2
nms_thresh: 0.5
num_gpus: 1
padding_minibatch: False
pixel_means: [102.9801, 115.9465, 122.7717]
pretrained_model: output_bs2/model_iter559999/
scales: [800]
score_thresh: 0.05
snapshot_iter: 10000
use_data_parallel: 0
use_flipped: True
use_gpu: True
warm_up_iter: 1000
------------------------------------------------
{'MomentumOptimizer_0': <paddle.fluid.dygraph.learning_rate_scheduler.ExponentialWithWarmupDecay object at 0x7f6a0b1ee490>}
Traceback (most recent call last):
  File "train.py", line 299, in <module>
    train()
  File "train.py", line 118, in train
    optimizer.load_dict(optimizer_load)
AttributeError: 'MomentumOptimizer' object has no attribute 'load_dict'
W0821 07:53:17.190511   135 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 9.0
W0821 07:53:17.194370   135 device_context.cc:269] device: 0, cuDNN Version: 7.2.
-----------  Configuration Arguments -----------
batch_size_per_im: 512
class_num: 81
data_dir: dataset/coco
dataset: coco2017
draw_threshold: 0.8
enable_ce: False
im_per_batch: 2
image_path: dataset/coco/val2017
learning_rate: 0.00125
log_window: 20
lr_steps: [480000, 640000]
max_iter: 720000
max_size: 1333
model_save_dir: output_bs2
nms_thresh: 0.5
num_gpus: 1
padding_minibatch: False
pixel_means: [102.9801, 115.9465, 122.7717]
pretrained_model: output_bs2/model_iter559999/
scales: [800]
score_thresh: 0.05
snapshot_iter: 10000
use_data_parallel: 0
use_flipped: True
use_gpu: True
warm_up_iter: 1000
------------------------------------------------
{'MomentumOptimizer_0': <paddle.fluid.dygraph.learning_rate_scheduler.ExponentialWithWarmupDecay object at 0x7f8bf3bb5490>}
loading annotations into memory...
Done (t=34.28s)
creating index...
index created!
_add_gt_annotations took 41.224s
Appending horizontally-flipped training examples...
Loaded dataset: coco2017
236574 roidb entries
Filtered 2042 roidb entries: 236574 -> 234532
train on coco2017 with 236574 roidbs
loading annotations into memory...
Done (t=1.29s)
creating index...
index created!
Loaded dataset: coco2017
5000 roidb entries
val on coco2017 with 5000 roidbs
2452241.2
573996.44
130605.93
39769.56
5513.215
Traceback (most recent call last):
  File "train.py", line 299, in <module>
    train()
  File "train.py", line 281, in train
    train_loop()
  File "train.py", line 213, in train_loop
    optimizer.minimize(loss)
AttributeError: 'ExponentialWithWarmupDecay' object has no attribute 'minimize'
