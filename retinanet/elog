x

[[0.6964692  0.28613934 0.22685145]
 [0.5513148  0.71946895 0.42310646]
 [0.9807642  0.6848297  0.4809319 ]]
L

[[1]
 [0]
 [2]]
size: 9 size_w: 3 size_h: 3

idx: 0
x: 0.696469187737

a: 0

d:0

label: [1]

c1: 1.0 c2: 0.0

Np: [2]

zn: [0.25] zp: [0.25]

p: 0.667404481301

term1: -0.0447301030327

term2: -0.490340513611

out_data: 0.0

out_data: 0.0111825261265

out_data: 0.0111825261265

idx: 1
x: 0.286139339209

a: 0

d:1

label: [1]

c1: 0.0 c2: 1.0

Np: [2]

zn: [0.25] zp: [0.25]

p: 0.571050717643

term1: -0.103089606074

term2: -0.27601553766

out_data: 0.0

out_data: 0.0

out_data: 0.0690038874745

idx: 2
x: 0.226851448417

a: 0

d:2

label: [1]

c1: 0.0 c2: 1.0

Np: [2]

zn: [0.25] zp: [0.25]

p: 0.556470896101

term1: -0.11530440742

term2: -0.251750942903

out_data: 0.0

out_data: 0.0

out_data: 0.0629377365112

idx: 3
x: 0.551314771175

a: 1

d:0

label: [0]

c1: 0.0 c2: 1.0

Np: [2]

zn: [0.25] zp: [0.25]

p: 0.634440574143

term1: -0.0608048880595

term2: -0.405061322144

out_data: 0.0

out_data: 0.0

out_data: 0.101265333593

idx: 4
x: 0.719468951225

a: 1

d:1

label: [0]

c1: 0.0 c2: 1.0

Np: [2]

zn: [0.25] zp: [0.25]

p: 0.67249006579

term1: -0.0425584231013

term2: -0.504810195887

out_data: 0.0

out_data: 0.0

out_data: 0.126202553511

idx: 5
x: 0.423106461763

a: 1

d:2

label: [0]

c1: 0.0 c2: 1.0

Np: [2]

zn: [0.25] zp: [0.25]

p: 0.604226359398

term1: -0.0789146070165

term2: -0.338406141292

out_data: 0.0

out_data: 0.0

out_data: 0.0846015363932

idx: 6
x: 0.980764210224

a: 2

d:0

label: [2]

c1: 0.0 c2: 1.0

Np: [2]

zn: [0.25] zp: [0.25]

p: 0.727259826033

term1: -0.0236902017636

term2: -0.687174657216

out_data: 0.0

out_data: 0.0

out_data: 0.171793669462

idx: 7
x: 0.684829711914

a: 2

d:1

label: [2]

c1: 1.0 c2: 0.0

Np: [2]

zn: [0.25] zp: [0.25]

p: 0.664815785197

term1: -0.0458657289197

term2: -0.48311732086

out_data: 0.0

out_data: 0.0114664323628

out_data: 0.0114664323628

idx: 8
x: 0.480931907892

a: 2

d:2

label: [2]

c1: 0.0 c2: 1.0

Np: [2]

zn: [0.25] zp: [0.25]

p: 0.617967907087

term1: -0.0702477596781

term2: -0.367468453017

out_data: 0.0

out_data: 0.0

out_data: 0.0918671116233

in /tmp/Paddle/python/paddle/fluid/tests/unittests/testsuite.py
X
[[0.01118253 0.06900389 0.06293774]
 [0.10126533 0.12620255 0.08460154]
 [0.17179367 0.01146643 0.09186711]]
X
in /tmp/Paddle/python/paddle/fluid/tests/unittests/testsuite.py
Label
[[1]
 [0]
 [2]]
Label
in /tmp/Paddle/python/paddle/fluid/tests/unittests/testsuite.py
Fg_num
[2]
Fg_num
in /tmp/Paddle/python/paddle/fluid/tests/unittests/testsuite.py
Out
[[0.01118253 0.06900389 0.06293774]
 [0.10126533 0.12620255 0.08460154]
 [0.17179367 0.01146643 0.09186711]]
Out
input_vars

{'X': name: "X"
type {
  type: LOD_TENSOR
  lod_tensor {
    tensor {
      data_type: FP32
      dims: 3
      dims: 3
    }
    lod_level: 0
  }
}
, 'Fg_num': name: "Fg_num"
type {
  type: LOD_TENSOR
  lod_tensor {
    tensor {
      data_type: INT32
      dims: 1
    }
    lod_level: 0
  }
}
, 'Label': name: "Label"
type {
  type: LOD_TENSOR
  lod_tensor {
    tensor {
      data_type: INT32
      dims: 3
      dims: 1
    }
    lod_level: 0
  }
}
}
X


Fg_num


Label


x: 0.0111825
a: 0
d: 0
g: 1
c1: 1
c2: 0
Np: 2
zn: 0.25
zp: 0.25
p: 0.502796
term1: -0.169976
term2: -0.176647
out_data: 0
out_data: 0.042494
out_data: 0.042494
x: 0.0690039
a: 0
d: 1
g: 1
c1: 0
c2: 1
Np: 2
zn: 0.25
zp: 0.25
p: 0.517244
term1: -0.153638
term2: -0.194836
out_data: 0
out_data: 0
out_data: 0.0487089
x: 0.0629377
a: 0
d: 2
g: 1
c1: 0
c2: 1
Np: 2
zn: 0.25
zp: 0.25
p: 0.515729
term1: -0.155292
term2: -0.192863
out_data: 0
out_data: 0
out_data: 0.0482157
x: 0.101265
a: 1
d: 0
g: 0
c1: 0
c2: 1
Np: 2
zn: 0.25
zp: 0.25
p: 0.525295
term1: -0.145076
term2: -0.205588
out_data: 0
out_data: 0
out_data: 0.051397
x: 0.126203
a: 1
d: 1
g: 0
c1: 0
c2: 1
Np: 2
zn: 0.25
zp: 0.25
p: 0.531509
term1: -0.138722
term2: -0.214203
out_data: 0
out_data: 0
out_data: 0.0535509
x: 0.0846015
a: 1
d: 2
g: 0
c1: 0
c2: 1
Np: 2
zn: 0.25
zp: 0.25
p: 0.521138
term1: -0.14945
term2: -0.199979
out_data: 0
out_data: 0
out_data: 0.0499948
x: 0.171794
a: 2
d: 0
g: 2
c1: 0
c2: 1
Np: 2
zn: 0.25
zp: 0.25
p: 0.542843
term1: -0.127681
term2: -0.230653
out_data: 0
out_data: 0
out_data: 0.0576633
x: 0.0114664
a: 2
d: 1
g: 2
c1: 1
c2: 0
Np: 2
zn: 0.25
zp: 0.25
p: 0.502867
term1: -0.169893
term2: -0.176733
out_data: 0
out_data: 0.0424732
out_data: 0.0424732
x: 0.0918671
a: 2
d: 2
g: 2
c1: 0
c2: 1
Np: 2
zn: 0.25
zp: 0.25
p: 0.522951
term1: -0.14753
term2: -0.20241
out_data: 0
out_data: 0
out_data: 0.0506026
F
======================================================================
FAIL: test_check_output (__main__.TestSigmoidFocalLossOp1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/tmp/Paddle/python/paddle/fluid/tests/unittests/test_sigmoid_focal_loss_op.py", line 111, in test_check_output
    self.check_output(atol=1e-2)
  File "/tmp/Paddle/python/paddle/fluid/tests/unittests/op_test.py", line 513, in check_output
    check_dygraph)
  File "/tmp/Paddle/python/paddle/fluid/tests/unittests/op_test.py", line 461, in check_output_with_place
    str(actual_t) + " in class " + self.__class__.__name__)
AssertionError: Output (Out) has diff at CPUPlace
Expect [[0.01118253 0.06900389 0.06293774]
 [0.10126533 0.12620255 0.08460154]
 [0.17179367 0.01146643 0.09186711]]
But Got[[0.04249401 0.04870889 0.04821566]
 [0.05139703 0.05355087 0.04999481]
 [0.05766335 0.04247317 0.05060257]] in class TestSigmoidFocalLossOp1

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (failures=1)
